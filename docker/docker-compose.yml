# Settings and configurations that are common for all containers
x-minio-common: &minio-common
  image: quay.io/minio/minio:RELEASE.2024-12-18T13-15-44Z
  command: server --console-address ":9001" http://minio{1...4}/data{1...2}
  expose:
    - "9000"
    - "9001"
  # environment:
    # MINIO_ROOT_USER: minioadmin
    # MINIO_ROOT_PASSWORD: minioadmin
  healthcheck:
    test: ["CMD", "mc", "ready", "local"]
    interval: 5s
    timeout: 5s
    retries: 5

services:
  # automatically put everything together
  auto:
    expose:
      - "8200"
    image: "ubuntu:jammy"
    container_name: setup
    depends_on:
      - vault
    # network_mode: "bridge"
    entrypoint: [ "sh", "-c", "/scripts/helper.sh"] 
    volumes:
      - type: bind
        source: ${PWD}/../scripts
        target: /scripts
      - type: bind
        source: ${PWD}/../terraform
        target: /terraform
      - type: bind
        source: ${PWD}/../secrets
        target: /secrets
    healthcheck:
      test: "exit 0"
      
  # visualize via Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    environment:
     - GF_SERVER_ROOT_URL=http://my.grafana.server/
     - GF_INSTALL_PLUGINS=grafana-clock-panel, grafana-simple-json-datasource
    ports:
     - '3000:3000'
    volumes:
      - "./../grafana/datasource.yaml:/etc/grafana/provisioning/datasources/prometheus_datasource.yaml"
      - ./../grafana/dashboard.yaml:/etc/grafana/provisioning/dashboards/main.yaml
      - ./../grafana/dashboards:/var/lib/grafana/dashboards

  # source control via GOGS
  gogs:
    image: gogs/gogs:latest
    container_name: gogs
    restart: always
    ports:
      - "10022:22"
      - "3001:3000"
    links:
      - postgres
    environment:
      - "RUN_CROND=true"
    volumes:
      - type: bind
        source: ${PWD}/../gogs/data
        target: /data
    depends_on:
      - postgres

  # OpenLDAP provides AuthMethod for Vault & Boundary
  openldap:
    image: osixia/openldap:latest
    container_name: openldap
    environment:
      LDAP_LOG_LEVEL: "256"
      LDAP_ORGANISATION: "Foo Inc."
      LDAP_DOMAIN: "foo.local"
      LDAP_BASE_DN: ""
      LDAP_ADMIN_PASSWORD: "admin"
      LDAP_CONFIG_PASSWORD: "config"
      LDAP_READONLY_USER: "false"
      #LDAP_READONLY_USER_USERNAME: "readonly"
      #LDAP_READONLY_USER_PASSWORD: "readonly"
      LDAP_RFC2307BIS_SCHEMA: "false"
      LDAP_BACKEND: "mdb"
      LDAP_TLS: "true"
      LDAP_TLS_CRT_FILENAME: "ldap.crt"
      LDAP_TLS_KEY_FILENAME: "ldap.key"
      LDAP_TLS_DH_PARAM_FILENAME: "dhparam.pem"
      LDAP_TLS_CA_CRT_FILENAME: "ca.crt"
      LDAP_TLS_ENFORCE: "false"
      LDAP_TLS_CIPHER_SUITE: "SECURE256:-VERS-SSL3.0"
      LDAP_TLS_VERIFY_CLIENT: "demand"
      LDAP_REPLICATION: "false"
      #LDAP_REPLICATION_CONFIG_SYNCPROV: 'binddn="cn=admin,cn=config" bindmethod=simple credentials="$$LDAP_CONFIG_PASSWORD" searchbase="cn=config" type=refreshAndPersist retry="60 +" timeout=1 starttls=critical'
      #LDAP_REPLICATION_DB_SYNCPROV: 'binddn="cn=admin,$$LDAP_BASE_DN" bindmethod=simple credentials="$$LDAP_ADMIN_PASSWORD" searchbase="$$LDAP_BASE_DN" type=refreshAndPersist interval=00:00:00:10 retry="60 +" timeout=1 starttls=critical'
      #LDAP_REPLICATION_HOSTS: "#PYTHON2BASH:['ldap://ldap.example.org','ldap://ldap2.example.org']"
      KEEP_EXISTING_CONFIG: "false"
      LDAP_REMOVE_CONFIG_AFTER_SETUP: "true"
      LDAP_SSL_HELPER_PREFIX: "ldap"
    tty: true
    stdin_open: true
    volumes:
      - /var/lib/ldap
      - /etc/ldap/slapd.d
      - /container/service/slapd/assets/certs/
    ports:
      - "30389:389"
      - "30636:636"

  # Web Based GUI for browsing LDAP
  phpldapadmin:
    image: osixia/phpldapadmin:latest
    container_name: phpldapadmin
    environment:
      PHPLDAPADMIN_LDAP_HOSTS: "openldap"
      PHPLDAPADMIN_HTTPS: "false"
    ports:
      - "8180:80"
    depends_on:
      - openldap

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./../prometheus/prometheus.yaml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

  # A touch of Consul
  consul:
    ports:
      - "8500:8500"
      - "8600:8600/udp"
    image: "hashicorp/consul:latest"
    container_name: consul
    cap_add:
      - IPC_LOCK
    volumes:
      - type: bind
        source: ${PWD}/../consul/data/server
        target: /opt/consul/data
      - type: bind
        source: ${PWD}/../consul/server.hcl
        target: /consul/config/consul-server.hcl
    entrypoint: [ "sh", "-c", "consul agent -server -config-file=/consul/config/consul-server.hcl -log-level=debug"] 
    depends_on:
      - auto
      - vault

  # Sprinkle Nomad
  nomad:
    ports:
      - "4646:4646"
    image: "hashicorp/nomad:latest"
    container_name: nomad
    cap_add:
      - IPC_LOCK
    environment:
      - 'NOMAD_ADDR=http://127.0.0.1:4646'
    volumes:
      - type: bind
        source: ${PWD}/../nomad/server.hcl
        target: /opt/nomad/config/nomad-server.hcl
    entrypoint: [ "sh", "-c", "nomad agent -config /opt/nomad/config/nomad-server.hcl -log-level=trace"] 
    depends_on:
      - auto
      - consul
      - vault
      
  nomad-agent:
    ports:
      - "4647:4646"
    image: "hashicorp/nomad:latest"
    container_name: nomad-agent
    cap_add:
      - IPC_LOCK
    environment:
      - 'NOMAD_ADDR=http://127.0.0.1:4646'
    volumes:
      - type: bind
        source: ${PWD}/../nomad/agent.hcl
        target: /opt/nomad/config/nomad-agent.hcl
    entrypoint: [ "sh", "-c", "nomad agent -config /opt/nomad/config/nomad-agent.hcl -log-level=trace"] 
    depends_on:
      - consul
      - nomad

  # tfe:
  #   image: images.releases.hashicorp.com/hashicorp/terraform-enterprise:<vYYYYMM-#>
  #   environment:
  #     TFE_LICENSE: "<Hashicorp license>"
  #     TFE_HOSTNAME: "<TFE hostname (DNS) e.g. terraform.example.com>"
  #     TFE_ENCRYPTION_PASSWORD: '<Encryption password>'
  #     TFE_OPERATIONAL_MODE: "disk"
  #     TFE_DISK_CACHE_VOLUME_NAME: "${COMPOSE_PROJECT_NAME}_terraform-enterprise-cache"
  #     TFE_TLS_CERT_FILE: "/etc/ssl/private/terraform-enterprise/cert.pem"
  #     TFE_TLS_KEY_FILE: "/etc/ssl/private/terraform-enterprise/key.pem"
  #     TFE_TLS_CA_BUNDLE_FILE: "/etc/ssl/private/terraform-enterprise/bundle.pem"
  #     TFE_IACT_SUBNETS: "<IACT subnet, eg. 10.0.0.0/8,192.168.0.0/24>"
  #   cap_add:
  #     - IPC_LOCK
  #   read_only: true
  #   tmpfs:
  #     - /tmp:mode=01777
  #     - /run
  #     - /var/log/terraform-enterprise
  #   ports:
  #     - "80:80"
  #     - "443:443"
  #   volumes:
  #     - type: bind
  #       source: /var/run/docker.sock
  #       target: /run/docker.sock
  #     - type: bind
  #       source: ./certs
  #       target: /etc/ssl/private/terraform-enterprise
  #     - type: bind
  #       source: <mounted_disk_path_on_host>
  #       target: /var/lib/terraform-enterprise
  #     - type: volume
  #       source: terraform-enterprise-cache
  #       target: /var/cache/tfe-task-worker/terraform

  # Secure with Vault
  vault:
    ports:
      - "5696:5696"
      - "8200:8200"
      - "8201:8201"
    image: "hashicorp/vault:latest"
    container_name: vault
    cap_add:
      - IPC_LOCK
    environment:
      - 'VAULT_ADDR=http://127.0.0.1:8200'
      - 'VAULT_DEV_ROOT_TOKEN_ID=root'
      - 'VAULT_SKIP_VERIFY=true'
    volumes:
      - type: bind
        source: ${PWD}/../vault/server.hcl
        target: /opt/vault/config/vault-server.hcl
    entrypoint: [ "sh", "-c", "vault server -config /opt/vault/config/vault-server.hcl -log-level=trace"] 
  
  # Run Vault Agent
  vault-agent:
    ports:
      - "8210:8200"
    image: "hashicorp/vault:latest"
    container_name: vault-agent
    cap_add:
      - IPC_LOCK
    environment:
      - 'VAULT_ADDR=http://127.0.0.1:8200'
      - 'VAULT_SKIP_VERIFY=true'
    volumes:
      - type: bind
        source: ${PWD}/../vault/agent.hcl
        target: /opt/vault/config/vault-agent.hcl
    entrypoint: [ "sh", "-c", "vault agent -config /opt/vault/config/vault-agent.hcl -log-level=trace"] 
    depends_on:
      - vault

  # Postgres for Boundary & Vault
  postgres:
    image: postgres:13
    container_name: postgres
    ports:
      - 5432:5432
    environment:
      - POSTGRES_DB=boundary
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 3s
      timeout: 5s
      retries: 5

  # Postgres Setup
  postgres-init:
    image: hashicorp/boundary:latest
    container_name: boundary-init
    command: ["database", "init", "-config", "/boundary/controller.hcl"]
    volumes:
      - "${PWD}/../boundary/controller.hcl:/boundary/controller.hcl:ro,z"
    environment:
      - BOUNDARY_PG_URL=postgresql://postgres:postgres@postgres/boundary?sslmode=disable
    cap_add:
      - IPC_LOCK
    depends_on:
      postgres:
        condition: service_healthy

  pgadmin:
    container_name: pgadmin
    image: dpage/pgadmin4:latest
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL:-pgadmin4@pgadmin.org}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD:-admin}
      PGADMIN_CONFIG_SERVER_MODE: 'False'
    volumes:
       - ${PWD}/../databases/postgres/pgadmin:/var/lib/pgadmin
    ports:
      - "${PGADMIN_PORT:-5050}:80"
    restart: unless-stopped

  boundary:
    image: hashicorp/boundary:latest
    cap_add:
      - IPC_LOCK
    # network_mode: "bridge"
    container_name: boundary
    command: ["server", "-config", "/boundary/boundary.hcl"]
    volumes:
      - "${PWD}/../boundary/controller.hcl:/boundary/boundary.hcl:ro,z"
    ports:
      - "9200:9200"
    environment:
      - BOUNDARY_PG_URL=postgresql://postgres:postgres@postgres/boundary?sslmode=disable
    depends_on:
      - postgres-init
      - auto
    healthcheck:
      test: ["CMD", "wget", "-O-", "http://127.0.0.1:9210"]
      interval: 3s
      timeout: 5s
      retries: 5

  boundary-worker-egress:
    image: hashicorp/boundary:latest
    cap_add:
      - IPC_LOCK
    # network_mode: "bridge"
    container_name: boundary-worker-egress
    command: ["server", "-config", "/boundary/worker.hcl"]
    volumes:
      - "${PWD}/../boundary/worker.hcl:/boundary/worker.hcl:ro,z"
    ports:
      - "9210:9210"
    environment:
      - BOUNDARY_CONTROLLER_URL=http://boundary:9200
    depends_on:
      - boundary
    healthcheck:
      test: ["CMD", "wget", "-O-", "http://127.0.0.1:9210"]
      interval: 3s
      timeout: 5s
      retries: 5

  boundary-worker-ingress:
    image: hashicorp/boundary:latest
    cap_add:
      - IPC_LOCK
    network_mode: "bridge"
    container_name: boundary-worker-ingress
    command: ["server", "-config", "/boundary/worker.hcl"]
    volumes:
      - "${PWD}/../boundary/worker.hcl:/boundary/worker.hcl:ro,z"
    ports:
      - "9211:9211"
    environment:
      - BOUNDARY_CONTROLLER_URL=http://boundary:9200
    depends_on:
      - boundary
    healthcheck:
      test: ["CMD", "wget", "-O-", "http://127.0.0.1:9211"]
      interval: 3s
      timeout: 5s
      retries: 5
      
  wait:
    # Install database client tools into busybox
    image: busybox:latest
    container_name: busybox
    command: >
      sh -c "apt install -y postgresql-client &&
            psql -w -U postgres -d boundary -c SELECT &&
            curl https://packages.microsoft.com/keys/microsoft.asc | sudo tee /etc/apt/trusted.gpg.d/microsoft.asc &&
            curl https://packages.microsoft.com/config/ubuntu/22.04/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list &&
            apt update &&
            apt install -y mssql-tools18 unixodbc-dev &&
            echo 'export PATH="$PATH:/opt/mssql-tools18/bin"' >> ~/.bash_profile &&
            source ~/.bash_profile &&
            echo 'export PATH="$PATH:/opt/mssql-tools18/bin"' >> ~/.bashrc &&
            source ~/.bashrc &&
            echo "deb [signed-by=/etc/apt/keyrings/apache-cassandra.asc] https://debian.cassandra.apache.org 41x main" | sudo tee -a /etc/apt/sources.list.d/cassandra.sources.list &&
            curl -o /etc/apt/keyrings/apache-cassandra.asc https://downloads.apache.org/cassandra/KEYS &&
            apt update &&
            apt install -y cassandra &&
            apt install -y mariadb-client &&
            apt install -y redis-tools
            "
    depends_on:
      - boundary

  # Private Database Targets
  cassandra:
    container_name: cassandra
    image: cassandra:3.11.9
    ports:
      - "9042:9042"
    environment:
      - "CASSANDRA_USER=admin"
      - "CASSANDRA_PASSWORD=changeme"
      - "MAX_HEAP_SIZE=256M"
      - "HEAP_NEWSIZE=128M"
    volumes:
      - cassandra-data:/var/lib/cassandra
      # - ./../databases/cassandra.yaml:/etc/cassandra/cassandra.yaml

  mssql:
    container_name: sql-server
    image: mcr.microsoft.com/mssql/server:2017-latest
    restart: always
    environment:
      ACCEPT_EULA: "Y"
      SA_PASSWORD: "Contraseña12345678"
      MSSQL_PID: "Evaluation"
    ports:
      - 1433:1433
    volumes:
      - mssql-data:/var/opt/mssql

  mysql:
    container_name: mysql
    image: mariadb:lts
    environment:
      - 'MARIADB_ROOT_PASSWORD=changeme'
    ports:
      - 3306:3306

  oracle:
    container_name: oracle
    image: container-registry.oracle.com/database/enterprise:latest
    environment:
      - ORACLE_SID=ORCLCDB
      - ORACLE_PDB=ORCLPDB1
      - ORACLE_PWD=changeme
    ports:
      - 1521:1521
    volumes:
      - oracle-data:/opt/oracle/oradata
      - oracle-backup:/opt/oracle/backup
    healthcheck:
      test: ["CMD", "sqlplus", "-L", "sys/Oracle_123@//localhost:1521/ORCLCDB as sysdba", "@healthcheck.sql"]
      interval: 30s
      timeout: 10s
      retries: 5

  redis:
    container_name: redis
    image: redis:latest
    command: >
      redis-server --requirepass changeme --protected-mode yes



# starts 4 docker containers running minio server instances.
# using nginx reverse proxy, load balancing, you can access
# it through port 9000.
  minio1:
    <<: *minio-common
    hostname: minio1
    volumes:
      - data1-1:/data1
      - data1-2:/data2

  minio2:
    <<: *minio-common
    hostname: minio2
    volumes:
      - data2-1:/data1
      - data2-2:/data2

  minio3:
    <<: *minio-common
    hostname: minio3
    volumes:
      - data3-1:/data1
      - data3-2:/data2

  minio4:
    <<: *minio-common
    hostname: minio4
    volumes:
      - data4-1:/data1
      - data4-2:/data2

  nginx:
    image: nginx:1.19.2-alpine
    hostname: nginx
    volumes:
      - ./../minio/nginx.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "9000:9000"
      - "9001:9001"
    depends_on:
      - minio1
      - minio2
      - minio3
      - minio4

## By default this config uses default local driver,
## For custom volumes replace with volume driver configuration.
volumes:
  cassandra-data:
  data1-1:
  data1-2:
  data2-1:
  data2-2:
  data3-1:
  data3-2:
  data4-1:
  data4-2:
  grafana-data:
  mssql-data:
  oracle-backup:
  oracle-data:
  terraform-enterprise-cache: